# Toxic-comment-classifier
## NLP multi-label classification using Tensorflow

<div align="center">
  <img src="https://github.com/AlaGrine/Toxic-Comment-Classification-with-Tensorflow/blob/main/stats/toxic_comments_freepik.jpg" >
</div>

## Project Overview <a name="overview"></a>

Negative online behaviors, like toxic comments, are likely to make people stop expressing themselves and leave a conversation.

Platforms struggle to identify and flag potentially harmful or offensive online comments, leading many communities to restrict or shut down user comments altogether.

## Problem statement <a name="prbStatement"></a>

[Kaggle](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data) issued a challenge to build a multi-label classification model that's able to detect different types of toxicity like threats, obscenity and insults, and thus help make online discussion more productive and respectful.

The data for the problem is a dataset of 159,571 comments from Wikipediaâ€™s talk page edits. These comments have been flagged for toxic behaviour by human reviewers.

